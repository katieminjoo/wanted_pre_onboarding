{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "592U6lXs3d2t"
   },
   "source": [
    "# Week2_3 Assignment\n",
    "\n",
    "## [BASIC](#Basic) \n",
    "- **Custom Dataset 클래스를 구현**할 수 있다.\n",
    "- train_dataset, valid_dataset으로 데이터셋을 나눌 수 있다.\n",
    "\n",
    "\n",
    "## [CHALLENGE](#Challenge)\n",
    "- **dynamic padding**을 만드는 `collate_fn`을 구현할 수 있다. \n",
    "- `DataLoader` 클래스를 사용해 **train_dataloaer와 valid_dataloader**를 만들 수 있다.\n",
    "\n",
    "\n",
    "## [ADVANCED](#Advanced)\n",
    "- 기존 코드의 data_iterator를 **data_loader로 대체**해 학습을 실행할 수 있다.\n",
    "\n",
    "### Reference\n",
    "-[DataLoader pytorch official document](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)   \n",
    "-[collate_fn 설명 영문 블로그](https://androidkt.com/create-dataloader-with-collate_fn-for-variable-length-input-in-pytorch/)   \n",
    "-[dynamic padding 설명 영문 블로그](https://mccormickml.com/2020/07/29/smart-batching-tutorial/#dynamic-padding)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KSX-wQA1RD1h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LNd-mYD5k2tb"
   },
   "outputs": [],
   "source": [
    "# seed\n",
    "seed = 7777\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gUR6vb3L3d2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# available GPUs : 1\n",
      "GPU name : GeForce RTX 3090\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device type\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0REKl4EvT9G1"
   },
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yeMAUqqk2td"
   },
   "source": [
    "### 데이터 로드 및 결측치 제거 (복습)\n",
    "- 해당 링크에서 `sample_df` 데이터 프레임을 로드하자\n",
    "  - df의 개수는 10,000개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2Ox_QgoIW7m"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zNHz7RtDIdTa"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에서 결측치 (na 값) 제거\n",
    "\n",
    "df = df.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XZoLAT-_JGdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 3)\n",
      "Label : 0    5000\n",
      "1    5000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {df.shape}\\nLabel : {df.label.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzUp9Z6Hk2tk"
   },
   "source": [
    "### `CustomDataset `클래스 구현\n",
    "- 클래스 정의\n",
    "  - 생성자 입력 매개변수 \n",
    "    - `input_data` : 리뷰 텍스트 리스트\n",
    "    - `target_data` : 레이블 (0 또는 1) list\n",
    "  - 생성자에서 생성할 변수\n",
    "    - `X` : `input_data`\n",
    "    - `Y` : `target_data`\n",
    "  - 메소드 \n",
    "    - `__len__()`\n",
    "      - 데이터 총 개수를 반환\n",
    "    - `__getitem__()`\n",
    "      - 해당 인덱스의 (input_data, target_data) 튜플을 반환\n",
    "  - 주의 사항\n",
    "    - `torch.utils.data.Dataset()` 클래스를 부모 클래스로 상속받아 구현한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ufvK9o1y75es"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kpJuYP5k75et"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    - input_data: list of string\n",
    "    - target_data: list of int\n",
    "    \"\"\"\n",
    "    def __init__(self, input_data:list, target_data:list) -> None:\n",
    "        self.X = input_data\n",
    "        self.Y = target_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O1IfgQ3i75et"
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(list(df['document'].values), list(df['label'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lhIyORYY75et"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.', 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map-stype dataset 클래스는 indexing이 가능함\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yUX4isDB75et"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 총 개수 확인 가능\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYl3lxKAk2to"
   },
   "source": [
    "###  `torch.utils.data.random_split` 함수를 사용해 데이터셋을 train, valid로 분리\n",
    "- 데이터 비율은 `train : valid = 9 : 1`으로 분리하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XMQKBb1j75et"
   },
   "outputs": [],
   "source": [
    "n_train = int(0.9 * len(dataset))\n",
    "n_valid = int(0.1 * len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ykrmlQc775et"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [n_train, n_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hAVrFb1575et"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xXqW0CTB75et"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT05JmBQk2tp"
   },
   "source": [
    "## Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BmAN83Ck2tq"
   },
   "source": [
    "### dynamic padding을 구현하는  `custom_collate_fn` 함수 구현 \n",
    "- batch (`List[Tuple(input, target)]`)를 입력받아 토크나이즈한 후 텐서 형태로 변형해 반환 ( `Tuple(Tensor(tokenized_input), Tensor(target))`)하는 `collate_fn()` 함수를 구현하라. \n",
    "- 함수 정의\n",
    "  - 입력 매개변수\n",
    "    - `batch` : (input(string), target(int)) 튜플을 담고 있는 리스트.  만약 `batch_size`가 32라면 리스트는 32개의 튜플을 갖고 있다. \n",
    "  - 조건\n",
    "    - input\n",
    "      - [BERT Tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer) 클래스의 `__call__()` 메소드 사용 방법을 읽고, `__call__()` 파라미터를 조정해 dynamic padding을 구현한다.\n",
    "      - 토크나이즈할 때 한 배치내 인풋들의 토큰 개수는 모두 동일할 수 있도록하라. 이때, 가장 긴 토큰을 가지고 있는 인풋을 기준으로 토큰 개수를 맞춘다. 즉, 토큰 개수가 모자란 인풋은 `[PAD]` 토큰을 추가한다. (이를 **dynamic padding**이라고 한다.) \n",
    "      - 토크나이저에서 반환된 값은 Tensor 타입이어야 한다. \n",
    "    - target\n",
    "      - target은 Tensor 타입으로 변형한다.\n",
    "  - 반환값\n",
    "    - (tensorized_input, tensorized_label) 튜플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-tJERGI4Fzk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JlcYCOyW3d2t"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "C_U_c-Mf3d2t"
   },
   "outputs": [],
   "source": [
    "tokenizer_bert = BertTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bqGJ0ryq75eu"
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    - batch: list of tuples (input_data(string), target_data(int))\n",
    "\n",
    "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
    "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
    "    토큰 개수는 배치 내 가장 긴 문장으로 해야함.\n",
    "    또한 최대 길이를 넘는 문장은 최대 길이 이후의 토큰을 제거하도록 해야 함\n",
    "    토크나이즈된 결과 값은 텐서 형태로 반환하도록 해야 함\n",
    "\n",
    "    한 배치 내 레이블(target)은 텐서화 함.\n",
    "\n",
    "    (input, target) 튜플 형태를 반환.\n",
    "    \"\"\"\n",
    "    global tokenizer_bert\n",
    "\n",
    "    input_list, target_list = [x for x,y in batch], [y for x,y in batch]\n",
    "\n",
    "\n",
    "    tensorized_input = tokenizer_bert(text = input_list,\n",
    "                                      return_tensors = 'pt',\n",
    "                                      padding = 'longest')\n",
    "\n",
    "\n",
    "    tensorized_label = torch.tensor(target_list)\n",
    "\n",
    "    return tensorized_input, tensorized_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLANqpNc75eu"
   },
   "source": [
    "### 위에서 구현한 `custom_collate_fn`함수를 적용해 DataLoader 인스턴스 생성\n",
    "- `train_dataloader`\n",
    "    - batch_size = 32\n",
    "    - collate_fn = 위에서 구현한 함수\n",
    "    - sampler = `RandomSampler()`\n",
    "        - `train_dataset`의 학습 데이터를 셔플링 함\n",
    "- `valid_dataloader`\n",
    "    - batch_size = 64\n",
    "    - collate_fn = 위에서 구현한 함수\n",
    "    - sampler = `SequentialSampler()`\n",
    "        - `valid_dataset`의 검증 데이터를 순차적으로 정렬함 (셔플X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f1fc7c87820>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader(dataset, batch_size = 32, sampler = RandomSampler(dataset), collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HO_HuNa-75eu"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size = 32, sampler = RandomSampler(dataset), collate_fn = custom_collate_fn)\n",
    "valid_dataloader = DataLoader(dataset, batch_size = 64, sampler = SequentialSampler(dataset), collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "id": "aDZ38Taw75eu",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([64, 69])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 73])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 69])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 87])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 82])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 95])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 55])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 120])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 87])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 80])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 61])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 88])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 89])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 79])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 86])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 85])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 71])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 99])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 89])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 84])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 47])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 84])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 88])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 88])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 82])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 90])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 80])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 82])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 75])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 84])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 85])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 95])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 83])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 93])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 63])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 116])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 97])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 88])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 83])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 84])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 88])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 72])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 70])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 91])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 76])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 90])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 91])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 76])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 82])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 76])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 75])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 68])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 83])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 75])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 77])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 84])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 82])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 92])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 83])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 88])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 92])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 79])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 76])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 117])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 70])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 76])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 85])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 72])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 73])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 97])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 88])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 86])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 83])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 74])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 86])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 72])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 85])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 63])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 74])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 77])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 57])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 70])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 80])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 57])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 76])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 83])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 69])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 74])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 65])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 79])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 98])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 73])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 65])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 85])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 68])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 58])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 75])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 66])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 74])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 96])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 73])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 65])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 74])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 91])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 54])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 91])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 74])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 77])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 80])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 60])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 90])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 63])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 71])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 72])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 95])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 77])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 76])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 77])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 78])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 83])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 89])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 71])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 96])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 93])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 81])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 87])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 74])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 73])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 63])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 86])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 73])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 84])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([64, 85])\n",
      "Batch target shape: torch.Size([64])\n",
      "Batch input shape: torch.Size([16, 73])\n",
      "Batch target shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# 배치마다 토큰 길이가 다른 것을 확인\n",
    "for input_batch, target_batch in valid_dataloader:\n",
    "    print(f\"Batch input shape: {input_batch['input_ids'].shape}\")\n",
    "    print(f\"Batch target shape: {target_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0K9zzAltk2ts"
   },
   "source": [
    "## Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2r2Pz_1nk2ts"
   },
   "source": [
    "### 어제(week2-2) 생성한 `train()` 함수의 입력값이었던 `data_iterator`를  `data_loader`로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "U0WbqVv62Zvy"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aw6VaI2yk2tt"
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader):\n",
    "    global loss_fct\n",
    "\n",
    "    # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
    "    total_loss, batch_loss, batch_count = 0,0,0\n",
    "\n",
    "    # model을 train 모드로 설정 & device 할당\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    # data iterator를 돌면서 하나씩 학습\n",
    "    for step, batch in enumerate(data_loader):\n",
    "        batch_count+=1\n",
    "\n",
    "        # tensor 연산 전, 각 tensor에 device 할당\n",
    "        batch = tuple(item.to(device) for item in batch)\n",
    "\n",
    "        batch_input, batch_label = batch\n",
    "\n",
    "        # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        logits = model(**batch_input)\n",
    "\n",
    "        # loss\n",
    "        loss = loss_fct(logits, batch_label)\n",
    "        batch_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 배치 10개씩 처리할 때마다 평균 loss를 출력\n",
    "        if (step % 10 == 0 and step != 0):\n",
    "            print(f\"Step : {step}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
    "\n",
    "            # 변수 초기화 \n",
    "            batch_loss, batch_count = 0,0\n",
    "\n",
    "    print(f\"Mean Loss : {total_loss/(step+1):.4f}\")\n",
    "    print(\"Train Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2XneduTk2tt"
   },
   "source": [
    "### 지금까지 구현한 함수와 클래스를 모두 불러와 `train()` 함수를 실행하자\n",
    "- fine-tuning 모델 클래스 (`CustomClassifier`)\n",
    "    - hidden_size = 768\n",
    "    - n_label = 2\n",
    "- 데이터 이터레이터 함수 (`data_iterator`)\n",
    "    - batch_size = 32\n",
    "- loss \n",
    "    - `CrossEntropyLoss()`\n",
    "- optimizer\n",
    "    - `AdamW()`\n",
    "    - lr = 2e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week2-2에서 구현한 클래스와 동일\n",
    "\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size : int, n_label : int):\n",
    "        super(CustomClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('klue/bert-base')\n",
    "        dropout_rate = 0.1\n",
    "        linear_layer_hidden_size = 32\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(hidden_size, linear_layer_hidden_size),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(dropout_rate),\n",
    "                                       nn.Linear(linear_layer_hidden_size, n_label),\n",
    "                                       )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        \n",
    "        outputs = self.bert(input_ids,\n",
    "                           attention_mask = attention_mask,\n",
    "                           token_type_ids = token_type_ids)\n",
    "        cls_token_last_hidden_states = outputs['pooler_output']\n",
    "        \n",
    "        logits = self.classifier(cls_token_last_hidden_states)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "w1ix-0Ztk2tu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 10, Avg Loss : 0.6845\n",
      "Step : 20, Avg Loss : 0.6374\n",
      "Step : 30, Avg Loss : 0.5533\n",
      "Step : 40, Avg Loss : 0.4452\n",
      "Step : 50, Avg Loss : 0.3971\n",
      "Step : 60, Avg Loss : 0.4125\n",
      "Step : 70, Avg Loss : 0.4078\n",
      "Step : 80, Avg Loss : 0.3879\n",
      "Step : 90, Avg Loss : 0.4245\n",
      "Step : 100, Avg Loss : 0.3902\n",
      "Step : 110, Avg Loss : 0.3839\n",
      "Step : 120, Avg Loss : 0.4017\n",
      "Step : 130, Avg Loss : 0.3941\n",
      "Step : 140, Avg Loss : 0.3309\n",
      "Step : 150, Avg Loss : 0.3178\n",
      "Step : 160, Avg Loss : 0.3585\n",
      "Step : 170, Avg Loss : 0.3224\n",
      "Step : 180, Avg Loss : 0.3778\n",
      "Step : 190, Avg Loss : 0.3194\n",
      "Step : 200, Avg Loss : 0.3240\n",
      "Step : 210, Avg Loss : 0.3640\n",
      "Step : 220, Avg Loss : 0.3464\n",
      "Step : 230, Avg Loss : 0.3540\n",
      "Step : 240, Avg Loss : 0.3687\n",
      "Step : 250, Avg Loss : 0.3347\n",
      "Step : 260, Avg Loss : 0.3341\n",
      "Step : 270, Avg Loss : 0.3303\n",
      "Step : 280, Avg Loss : 0.3740\n",
      "Step : 290, Avg Loss : 0.3567\n",
      "Step : 300, Avg Loss : 0.3197\n",
      "Step : 310, Avg Loss : 0.3443\n",
      "Mean Loss : 0.3905\n",
      "Train Finished\n"
     ]
    }
   ],
   "source": [
    "# 모델\n",
    "model = CustomClassifier(hidden_size = 768, n_label = 2)\n",
    "\n",
    "# 데이터로더\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset, batch_size = batch_size, sampler = RandomSampler(dataset), collate_fn = custom_collate_fn)\n",
    "\n",
    "# 로스 및 옵티마이저\n",
    "loss_fct = CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                 lr = 2e-5,\n",
    "                 eps = 1e-8)\n",
    "\n",
    "# 학습 시작\n",
    "train(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Katie Minjoo Kim - Week2_3_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
